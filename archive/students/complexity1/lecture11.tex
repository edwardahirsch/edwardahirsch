\documentclass[12pt,fleqn,a4paper]{book}
% 
% Packages used:
%
\usepackage[koi8-r]{inputenc}
\usepackage[russian,english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
%
% Common customization:
%
\input defs
%
% The document
%
\begin{document}
\selectlanguage{russian}
%
% Lecture title
%
\lecture{11}{Уменьшение вероятности ошибки алгоритма из $\BPP$ с использованием небольшого количества случайных битов}{А. Куликов}
%
% The lecture
%
Целью данной лекции будет построение алгоритма, уменьшающего вероятность ошибки алгоритма (обозначим его буквой $\Lambda$) из класса $\BPP$ (а точнее, алгоритма, распознающего язык из $\BPP$) до $2^{-k}$ и использующего всего $O(r+k)$ случайных битов, где $r$ -- количество случайных битов, используемых алгоритмом $\Lambda $.
%, а $k$ -- количество раз, которое $\Lambda$ будет повторен в искомом алгоритме.

Говоря неформально, наша конструкция выглядит следующим образом. Сначала мы зададим граф, каждой вершине которого будет соответствовать %<<почти случайная>> 
$r$-битовая строчка (эти строчки мы и будем использовать в
алгоритме $\Lambda $ в качестве случайной строки). (Итого в нашем графе
имеется $n=2^r$ вершин.) Используя настоящие случайные биты, выберем одну из вершин этого графа и дадим соответствующую ей строчку алгоритму $\Lambda$. Далее, опять же используя случайные биты (но лишь $O(1)$ штук), перейдем из начальной вершины по ребрам графа в другую вершину, вследствие чего получим новую псевдослучайную строчку, которую и подадим $\Lambda$. Из этой вершины опять перейдем в другую и$\;$т.$\;$д. --- всего обойдем $O(k)$ вершин.
Ответ, как и обычно, дадим <<большинством голосов>>.    
%Настоящие же случайные биты мы будем использовать лишь для хождения по этому графу,
%то есть для определения следующей псевдослучайной строки. Будет доказано, что эти строки помогают %уменьшить вероятность ошибки до $2^{-k}$. 

Теперь перейдем к формальным определениям.
Приведем необходимый нам для последующего определения факт из курса алгебры:
\begin{fact}
Пусть $\lambda_1 \geq \lambda_2 \geq ... \geq \lambda_n$ -- собственные числа матрицы смежности 
связного двудольного\footnote{Здесь и далее под двудольным графом мы будем понимать лишь графы, содержащие равные количества вершин в обеих долях.} $d$-регулярного графа. Тогда
\begin{enumerate}
\item[(1)]  $\lambda_1 = d = -\lambda_n,$
\item[(2)]  $\lambda_1 > \lambda_2$,
\item[(3)]  собственный вектор ортонормального собственного базиса, соответствующий собственному числу  $\lambda_1$, имеет вид 
$(1, ..., 1)\cdot 2^{-n/2}$.
\end{enumerate}
\end{fact}

\begin{definition}
(Бесконечное) семейство (различных между собой) двудольных $d$-регулярных графов
называется семейством $\varepsilon$-расширителей,
если
% выполнено одно из следующих условий:
%\begin{enumerate}
%\item для любого графа этого семейства окрестность любого подмножества вершин одной доли содержит достаточно большое количество вершин (как здесь понимать словосочетание <<достаточно большое>>, мы определать не будем; интуитивно же это следует понимать как "почти всегда большее");
%\item 
для любого графа из этого семейства $\lambda_1 - \lambda_2 \geq \varepsilon$.
%\end{enumerate}
\end{definition}

Это не слишком традиционное определение, но оно в определенном смысле
эквивалентно другим определениям расширителей.
%Можно доказать, что эти два условия в некотором смысле эквивалентны (конечно, сформулировав сами условия строго). Мы же делать этого не будем, так как первое условие нам не понадобится. 

Приведем теперь конструкцию семейства графов-расширителей. Степень каждой вершины каждого из этих графов будет равняться $7$, сам же граф будет содержать ровно по $m^2$ вершин в каждой доле. 
Проиндексируем все вершины каждой из долей парами чисел $(x, y)$, где $x, y \in [0..m-1]$. Вершину $(x, y)$ левой доли
соединим с вершинами $(x, y), (x, 2x+y), (x, 2x+y+1), (x, 2x+y+2), (x+2y, y), (x+2y+1, y), (x+2y+2, y)$ правой доли (естественно, все числа в индексах вершин здесь берутся по модулю $m$). Доказывать, что построенное семейство графов является семейством расширителей, мы не будем. (Отметим, что само семейство строится детерминированно, причем строить сами графы нам, на самом деле, не нужно: ведь мы можем <<вычислить>> всех соседей любой вершины по ее индексу $(x,y)$.)

Мы устроим случайное блуждание на этом графе.
Зададим матрицу перехода марковской цепи таким образом: 
$B_0 = E/2 + A/14$, где $E$ --- единичная матрица, а $A$ --- матрица смежности графа размера $2^r$ 
из построенного семейства графов
(возможно, здесь число $r$ будет отличаться на $1$ от его начального значения, ведь все графы в построенном семействе имеют размер $2m^2$, но на оценку это не повлияет). Такая матрица перехода задает следующие действия: с вероятностью $1/2$ мы остаемся в текущей вершине и с вероятностью $1/2$ идем (равновероятно) в одного из соседей этой вершины. Ясно, что на один переход нам потребуется не более четырех случайных битов.
Всего же переходов от одной псевдослучайной строчки к другой будем делать $\beta$ штук, где $\beta$ --- некоторая фиксированная константа, удовлетворяющая нервенству $\lambda_2^{\beta} < 1/10$, где $\lambda_2$ -- второе собственное число матрицы $B_0$.
После этого будем запускать на полученной случайной строчке алгоритм $\Lambda$
и совершать следующие $\beta$ переходов. Всего мы используем $k'=O(k)$ случайных
строчек, проделав для этого $\beta k'=O(k)$ переходов.
\emph{Отныне и до конца лекции нас будет интересовать матрица $B=B_0^\beta$
перехода за $\beta$ шагов
(заметим, что у этой матрицы такие собственные числа: $\lambda_1=1$, $\lambda_2<\frac{1}{10}$, остальные --- меньше, но неотрицательны; первый собственный вектор --- $2^{-r/2}(1,\ldots,1)$).}

Итак, алгоритм описан, в нем действительно используется лишь
$O(r+k)$ случайных битов. Докажем его корректность.

Для удобства будем считать, что алгоритм $\Lambda$ ошибается с вероятностью, меньшей $1/100$.
Введем следующие обозначения: 
$\bar{W}$ --- матрица размера $2^r\times 2^r$, в которой 1 записаны лишь на диагонали в местах, соответствующих 
$r$-битовым строкам, на которых алгоритм $\Lambda$ ошибается; $W = E - \bar{W}$ (в ней 1 стоят в <<верных>>
местах); %$B$ --- матрица перехода нашей Марковской цепи за $\beta$ шагов (то есть ее $\lambda_2 < 1/10$);
$p_0 = 2^{-r}(1,\ldots,1)$ --- начальная строка состояния нашей Марковской цепи (данная строка показывает, что начальную вершину мы выбираем равновероятно). Тогда 
$pB$ --- распределение вероятности после одного перехода из распределения $p$, 
$||p\bar{W}||_1$ -- вероятность быть в <<хорошей>> 
(такой, на которой $\Lambda$ дает верный ответ)
строке, $||pW||_1$ -- в <<плохой>>. 
Для доказательства корректности построенного нами алгоритма достаточно показать, что вероятность того, что большинство строчек, выданных алгоритму $\Lambda$, будут <<плохими>>, мала.

Пусть $S_i=W$, если $i$-я поданная на вход $\Lambda$ строчка <<хорошая>>, 
и $S_i=\bar{W}$ в противном случае.
Тогда верна следующая лемма.

\begin{lemma}\label{lem:S1Sk}
$P\{S_1, \ldots, S_{k'}\} = ||p_0BS_1\ldots BS_{k'}||_1$ (здесь под $S_i$-ым в левой части равенства мы понимаем соответствующее этой матрице событие <<хорошести>> $i$-ой входной строчки).
\end{lemma}

Напомним, что нам нужно показать, что если среди $S_i$-ых много <<плохих>> событий, то вероятность появления такой последовательности мала. Покажем мы это, воспользовавшись следующей леммой.

\begin{lemma}\label{lem:pBW} $\forall p$\hfill
\begin{enumerate}
\item
$||pBW||_2 \leq ||p||_2$
\item
$||pB\bar{W}||_2 \leq \frac{1}{5}\cdot ||p||_2$
\end{enumerate}
\end{lemma}
\begin{proof}

\begin{enumerate}
\item
$||pBW||_2 \leq ||pB||_2 = ||\sum{c_i\lambda_ie_i}||_2 = \sqrt{\sum{c_i^2\lambda_i^2}} \leq \sqrt{\sum{c_i^2}} = ||p||_2$.
Здесь $\{e_i\}$ --- ортонормированный базис из собственных векторов матрицы $B$; последнее неравенство верно в силу того, что собственные числа $B$ заключены в отрезке $[-1;1]$. 
\item
Разложим вектор $p$ в сумму: $p = x + y$, где $x = c_1e_1, y = \sum_{i \geq 2}{c_ie_i}$. Тогда 
$||pB\bar{W}||_2 \leq ||xB\bar{W}||_2 + ||yB\bar{W}||_2$. Оценим отдельно каждое слагаемое.
\begin{itemize}
\item
$||xB\bar{W}||_2 = ||c_1\lambda_1e_1\bar{W}||_2 = 
||c_1e_1\bar{W}||_2 \leq c_1/10 \leq \frac{1}{10} ||p||_2$. Предпоследнее неравенство здесь выполнено по причине того, что в $\bar{W}$ достаточно <<мало>> $1$ (т.к. алгоритм $\Lambda$ ошибается с вероятностью, меньшей $1/100$), а все компоненты $e_1$ равны между собой. 
\item
$||yB\bar{W}||_2 = ||\sum_{i \geq 2}{c_i\lambda_ie_i\bar{W}}||_2 \leq ||\sum_{i \geq 2}{c_i\lambda_ie_i}||_2 =
\sqrt{\sum_{i \geq 2}{c_i^2\lambda_i^2}} \leq \sqrt{\sum_{i \geq 2}{c_i^2\lambda_2^2}} = \lambda_2||p||_2 \leq \frac{1}{10}||p||_2.$
\end{itemize}
\end{enumerate}
\end{proof}

Итак, вероятность появления конкретной <<плохой>> последовательности оценивается следующим образом:
\begin{eqnarray*}
P\{S_1,\ldots, S_{k'}\} 
&=& ||p_0BS_1\ldots BS_{k'}||_1\\
&\leq& 2^{r/2}||p_0BS_1\ldots BS_{k'}||_2\\
&\leq& 2^{r/2} \cdot 5^{-k'/2} \cdot 2^{-r} \cdot 2^{r/2} \\&=&
5^{-k'/2}.\end{eqnarray*}
Тогда вероятность того, что построенный нами алгоритм получит плохую последовательность,
не превосходит $(2\cdot 5^{-1/2})^{k'}$ (здесь мы воспользовались тем, что количество плохих последовательностей 
не превосходит количества последовательностей вообще, равного $2^{k'}$). 
Выбрав $k'=7k$, получаем искомую вероятность ошибки $\le 2^{-k}$.
\end{document}
